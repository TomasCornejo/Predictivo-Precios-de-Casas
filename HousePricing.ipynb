{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tt_split \n",
    "from sklearn.preprocessing import StandardScaler as SScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as Lreg\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.neural_network import MLPClassifier as MLPC\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error as MSLE #se usa este indicador porque es lo que se pide optimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargando train set\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diferencia entre set de entrenamiento y prueba\n",
    "#Esta parte es necesaria dada la competencia, no seria un tema si fuera un caso real producto \n",
    "#de que nos encargariamos de que la distribucion tuviera las mismas caracteristicas en \n",
    "#entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_info = df.describe().iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info = df_test.describe().iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3SsnPorch        0.900149\n",
       "Id               0.666438\n",
       "LowQualFinSF     0.649353\n",
       "PoolArea         0.581627\n",
       "MiscVal          0.252354\n",
       "BsmtHalfBath     0.117606\n",
       "ScreenPorch      0.117406\n",
       "BsmtFinSF2       0.115357\n",
       "EnclosedPorch    0.094426\n",
       "LotArea          0.071052\n",
       "2ndFlrSF         0.064499\n",
       "Fireplaces       0.054702\n",
       "MoSold           0.035670\n",
       "OpenPorchSF      0.034227\n",
       "MasVnrArea       0.029552\n",
       "BsmtUnfSF        0.023355\n",
       "LotFrontage      0.021429\n",
       "BsmtFullBath     0.020973\n",
       "TotRmsAbvGrd     0.020769\n",
       "GrLivArea        0.019796\n",
       "HalfBath         0.013824\n",
       "WoodDeckSF       0.011481\n",
       "TotalBsmtSF      0.010813\n",
       "BsmtFinSF1       0.010100\n",
       "MSSubClass       0.008384\n",
       "1stFlrSF         0.005268\n",
       "BedroomAbvGr     0.004355\n",
       "KitchenAbvGr     0.003914\n",
       "OverallCond      0.003878\n",
       "FullBath         0.003737\n",
       "OverallQual      0.003371\n",
       "YearRemodAdd     0.000606\n",
       "GarageCars       0.000569\n",
       "GarageArea       0.000447\n",
       "GarageYrBlt      0.000397\n",
       "YearBuilt        0.000046\n",
       "YrSold           0.000023\n",
       "SalePrice             NaN\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diferencia Absoluta\n",
    "abs((train_info - test_info)/test_info).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explorando las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport as PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-7cfa9827ed69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train_ds.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprof2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test_ds.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PR' is not defined"
     ]
    }
   ],
   "source": [
    "prof = PR(df)\n",
    "prof.to_file(output_file='train_ds.html')\n",
    "\n",
    "prof2 = PR(df_test)\n",
    "prof.to_file(output_file='test_ds.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables Continuas\n",
    "def get_var_con(df):\n",
    "    df_con = df[['OverallQual','OverallCond','YearBuilt',\\\n",
    "             'TotalBsmtSF','GarageYrBlt','Fireplaces',\\\n",
    "             'GarageArea','FullBath','HalfBath',\\\n",
    "             '2ndFlrSF','GrLivArea','YearRemodAdd',\\\n",
    "             'MasVnrArea'\n",
    "             ]]\n",
    "    return df_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de Preproceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diccionario de cambios\n",
    "Variables_dict = [ \\\n",
    "[['Utilities'],{'AllPub':4,'NoSewr':3, 'NoSeWa':2, 'ELO':1}], \\\n",
    "[['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC',\\\n",
    "  'KitchenQual','FireplaceQu','GarageQual','GarageCond','PoolQC'] \\\n",
    " , {'Ex':5,'Gd':4, 'TA':3, 'Fa':2, 'Po':1, np.nan : 0}], \\\n",
    "[['BsmtExposure'] , {'Gd':4,'Av':3, 'Mn':2, 'No':1, np.nan : 0}], \\\n",
    "[['BsmtFinType1','BsmtFinType2'] , {'GLQ':6,'ALQ':5, 'BLQ':4, 'Rec':3,'LwQ':2,'Unf':1,np.nan : 0}], \\\n",
    "[['CentralAir'],{'N':0, 'Y':1 ,np.nan : 0}], \\\n",
    "[['GarageFinish'] , {'Fin':3,'RFn':2, 'Unf':1, np.nan : 0}], \\\n",
    "[['Fence'] , {'GdPrv':4,'MnPrv':3, 'GdWo':2, 'MnWw':1, np.nan : 0}] \\\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazo_dict(df, x, dic):\n",
    "    df[x] = df[x].map(dic).fillna(df[x])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_dicc(df):\n",
    "    #Variables para Cambio por diccionario\n",
    "    df_dict = df[['Utilities',\n",
    "    'ExterQual','ExterCond','BsmtQual','BsmtCond',\n",
    "    'BsmtExposure',\n",
    "    'BsmtFinType1',\n",
    "    'BsmtFinType2',\n",
    "    'HeatingQC',\n",
    "    'CentralAir',\n",
    "    'KitchenQual',\n",
    "    'FireplaceQu',\n",
    "    'GarageFinish',\n",
    "    'GarageQual',\n",
    "    'GarageCond',\n",
    "    'PoolQC',\n",
    "    'Fence']]\n",
    "    for elemento in Variables_dict:\n",
    "        for columna in elemento[0]:\n",
    "            df_dict = reemplazo_dict(df_dict, columna, elemento[1])  \n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AgregaOneHotEncoding(df, x):\n",
    "    lista_tipos = tuple(df[x].unique())\n",
    "    sub_df = pd.DataFrame(lista_tipos, columns=[x])\n",
    "    dum_df = pd.get_dummies(sub_df, columns = [x], prefix = [x] )\n",
    "    sub_df = sub_df.join(dum_df)\n",
    "    sub_df\n",
    "    \n",
    "    df_final = df.merge(sub_df, how='left', on=x)\n",
    "    df_final = df_final.drop(x,1)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_OHE(df):\n",
    "    #Variables para OneHotEncoding\n",
    "    df_OHE = df[['MSZoning',\n",
    "    'Street',\n",
    "    'Alley',\n",
    "    'LotShape',\n",
    "    'LandContour',\n",
    "    'LotConfig',\n",
    "    'LandSlope',\n",
    "    'Neighborhood',\n",
    "    'Condition1',\n",
    "    'Condition2',\n",
    "    'BldgType',\n",
    "    'HouseStyle',\n",
    "    'RoofStyle',\n",
    "    'RoofMatl',\n",
    "    'Exterior1st',\n",
    "    'Exterior2nd',\n",
    "    'MasVnrType',\n",
    "    'Foundation',\n",
    "    'Heating',\n",
    "    'Electrical',\n",
    "    'Functional',\n",
    "    'GarageType',\n",
    "    'PavedDrive',\n",
    "    'MiscFeature',\n",
    "    'SaleType',\n",
    "    'SaleCondition']]\n",
    "    \n",
    "    for columna in  list(df_OHE.columns):\n",
    "        df_OHE = AgregaOneHotEncoding(df_OHE, columna)\n",
    "    return df_OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(df,train_flg):\n",
    "    \n",
    "    df['GarageYrBlt'] = df['GarageYrBlt'].fillna(0)\n",
    "    df['MasVnrArea'] = df['MasVnrArea'].fillna(0)\n",
    "    df['GarageArea'] = df['GarageArea'].fillna(0)\n",
    "    \n",
    "        \n",
    "    Scale = SScaler()\n",
    "\n",
    "    if train_flg == 1:\n",
    "        y = df['SalePrice'].values\n",
    "        \n",
    "    \n",
    "        X1 = get_var_con(df)\n",
    "        \n",
    "        X2 = get_var_dicc(df)\n",
    "        \n",
    "        X3 = get_var_OHE(df)\n",
    " \n",
    "        \n",
    "        X = pd.concat([X1,X2,X3], axis=1).values\n",
    "\n",
    "        X_out = pd.concat([X1,X2,X3], axis=1)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = tt_split(X, y, train_size= 0.67, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "        X_train = Scale.fit_transform(X_train)\n",
    "\n",
    "        X_test = Scale.fit_transform(X_test)\n",
    "\n",
    "        X_train = np.nan_to_num(X_train, nan = 0)\n",
    "        X_test = np.nan_to_num(X_test, nan = 0)\n",
    "        \n",
    "        return  X_train, X_test, y_train, y_test, X_out\n",
    "    else:\n",
    "        \n",
    "        X1 = get_var_con(df)\n",
    "        \n",
    "        X2 = get_var_dicc(df)\n",
    "        \n",
    "        X3 = get_var_OHE(df)\n",
    " \n",
    "        \n",
    "        X = pd.concat([X1,X2,X3], axis=1)\n",
    "        \n",
    "        for element in [item for item in list(data_train.columns) if item not in list(X.columns)]:\n",
    "            X[element] = 0\n",
    "        \n",
    "        X = X[list(data_train.columns)].values\n",
    "        \n",
    "        X_out = pd.concat([X1,X2,X3], axis=1)\n",
    "        \n",
    "        X_val = Scale.fit_transform(X)\n",
    "        \n",
    "        Id = df['Id'].values\n",
    "        \n",
    "        X_val = np.nan_to_num(X_val, nan = 0)\n",
    "        \n",
    "        return Id , X_val , X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion que prueba Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prueba_modelo(X_train, X_test, y_train, y_test , modelo_input, nombre_modelo):\n",
    "    modelo = modelo_input \n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    np.clip(a= y_pred, a_min=0, a_max=None , out=y_pred)\n",
    "    error = MSLE(y_test, y_pred)\n",
    "    nombre = nombre_modelo\n",
    "    modelo_entrenado = modelo\n",
    "    return [nombre, error, modelo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelos\n",
    "Modelos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Linear'\n",
    "model = Lreg()\n",
    "Modelos.append([name,model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Tree'\n",
    "model = DTR()\n",
    "Modelos.append([name,model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'RandomForest'\n",
    "model = RFR()\n",
    "Modelos.append([name,model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'MultiLayer'\n",
    "model = MLPC()\n",
    "Modelos.append([name,model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Linear',\n",
       "  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)],\n",
       " ['Tree',\n",
       "  DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                        max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best')],\n",
       " ['RandomForest',\n",
       "  RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                        random_state=None, verbose=0, warm_start=False)],\n",
       " ['MultiLayer',\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "                hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "                momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "                power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "                tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "                warm_start=False)]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, data_train = Preprocessing(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for modelo in Modelos:\n",
    "    Output.append(Prueba_modelo(X_train, X_test, y_train, y_test, modelo[1],modelo[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Linear',\n",
       "  609.9625399655984,\n",
       "  LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)],\n",
       " ['Tree',\n",
       "  0.042896006780183384,\n",
       "  DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                        max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best')],\n",
       " ['RandomForest',\n",
       "  0.022770563675996093,\n",
       "  RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                        random_state=None, verbose=0, warm_start=False)],\n",
       " ['MultiLayer',\n",
       "  0.05715290679837373,\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "                beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "                hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "                learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "                momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "                power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "                tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "                warm_start=False)]]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaled\n",
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Id, X_val, data_test = Preprocessing(df_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Output[2][2]\n",
    "Upload = modelo.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultado = pd.DataFrame(list(zip(Id,Upload)), columns = ['Id','SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultado.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
